import os
import re
from pathlib import Path
from typing import Optional
from typing import AsyncGenerator, Dict, Any, List, Tuple, Union
import json
from langchain.prompts import (
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from dataclasses import dataclass, field
from docx import Document
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from function import normalize,lcs_similarity,safe_eval, json_to_readable
from auxilary import WordDocumentProcessor, ChapterReaderTool


@dataclass
class ReviewRule:
    """è¯„å®¡è§„åˆ™ç±»"""
    name: str
    criteria: str
    score_range: str
    details: str = ""
    reference_paragraphs: List[int] = field(default_factory=list)

    # æ–°å¢å±‚çº§ç»“æ„æ”¯æŒ
    section: str = ""  # å¤§é¡¹åç§°
    subsection: str = ""  # å­é¡¹åç§°
    section_score_range: str = ""  # å¤§é¡¹åˆ†å€¼èŒƒå›´
    subsection_score_range: str = ""  # å­é¡¹åˆ†å€¼èŒƒå›´

class ReviewSystem:
    """è¯„å®¡ç³»ç»Ÿä¸»ç±»"""

    def __init__(self, chapters_dir: str = "./chapters"):
        self.chapters_dir = Path(chapters_dir)
        self.chapter_reader = ChapterReaderTool(chapters_dir)
        self.review_rules = []
        self.rules_learned = False
        self.principle_chapter_name: Optional[str] = None  # å­˜å‚¨åŒ…å«è¯„å®¡åŸåˆ™çš„ç« èŠ‚å
        self.scoring_tables = []  # æ–°å¢ï¼šå­˜å‚¨æ‰€æœ‰è¯„åˆ†è¡¨æ ¼ä¿¡æ¯
        # åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹
        self.llm = ChatOpenAI(
            base_url="http://192.168.1.224:8000/v1",
            api_key="EMPTY",
            model="qwen3-32b",
            temperature=0.1,
            streaming = True,
        )

        # åˆ›å»ºä»£ç†å·¥å…·
        self.tools = [self.chapter_reader]
        self.agent = self._create_agent()

    def _create_agent(self):
        """åˆ›å»ºå¸¦æœ‰ç« èŠ‚é˜…è¯»å·¥å…·çš„ä»£ç†"""
        from langchain.agents import AgentExecutor, create_tool_calling_agent
        from langchain_core.prompts import ChatPromptTemplate

        # ç”¨åŸå§‹å­—ç¬¦ä¸²å’Œ Markdown ä»£ç å—ï¼Œé¿å…æ‰‹åŠ¨è½¬ä¹‰å¼•å·å’Œå¤§æ‹¬å·å¯¼è‡´çš„æ§åˆ¶å­—ç¬¦é—®é¢˜
        system_prompt = r"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£è¯„å®¡ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†ææ–‡æ¡£å†…å®¹ï¼Œæå–æ‰€æœ‰è¯„å®¡å¾—åˆ†ç›¸å…³çš„è¡¨æ ¼å†…å®¹ã€‚  
        æ–‡æ¡£ä¸­å¯èƒ½åŒ…å«å¤šä¸ªè¯„åˆ†è¡¨æ ¼ï¼Œæ¯”å¦‚æŠ€æœ¯è¯„åˆ†ç»†åˆ™ã€å•†åŠ¡è¯„åˆ†ç»†åˆ™ã€æŠ¥ä»·è¯„åˆ†ç»†åˆ™ç­‰ã€‚  
        ä½ å¯ä»¥ä½¿ç”¨å·¥å…·æ¥æŸ¥é˜…æ–‡æ¡£çš„ä»»ä½•ç« èŠ‚ã€‚  
        è¯·ä»”ç»†åˆ†æå†…å®¹ï¼Œæå–å‡ºæ‰€æœ‰çš„è¯„åˆ†è¡¨æ ¼å’Œè§„åˆ™ï¼Œå¹¶è¯†åˆ«æ¯ä¸ªè¡¨æ ¼çš„å±‚çº§ç»“æ„ã€‚

        ä¸‹é¢è¯·æŒ‰ç…§ **ä¸¥æ ¼çš„ JSON** æ ¼å¼è¿”å›æ‰€æœ‰çš„è¯„å®¡è¡¨æ ¼ï¼ˆä¸è¦åŒ…å«å¤šä½™æ³¨é‡Šï¼‰ï¼Œæ³¨æ„è¦åŒ…å«æ–‡æ¡£ä¸­çš„æ¯ä¸€ä¸ªè¯„åˆ†è¡¨æ ¼ï¼š

        ```json
        {{
          "scoring_tables": [
            {{
              "table_name": "è¡¨æ ¼åç§°ï¼Œä¾‹å¦‚ï¼šæŠ€æœ¯è¯„åˆ†ç»†åˆ™",
              "table_description": "è¡¨æ ¼çš„æ–‡å­—æè¿°",
              "total_score_range": "æ€»åˆ†çš„å–å€¼èŒƒå›´ï¼Œæ¯”å¦‚ 0ï½100",
              "weight": "æƒé‡ï¼ˆå¦‚æœæœ‰ï¼‰",
              "sections": [
                {{
                  "section_name": "å¤§é¡¹åç§°",
                  "section_score_range": "å¤§é¡¹åˆ†å€¼èŒƒå›´",
                  "subsections": [
                    {{
                      "subsection_name": "å­é¡¹åç§°",
                      "subsection_score_range": "å­é¡¹åˆ†å€¼èŒƒå›´",
                      "items": [
                        {{
                          "item_name": "å…·ä½“è¯„åˆ†é¡¹åç§°",
                          "description": "è¯¦ç»†è¯„åˆ†æ ‡å‡†æè¿°",
                          "score_range": "å­é¡¹åˆ†å€¼èŒƒå›´",
                          "scoring_method": "è¯„åˆ†æ–¹æ³•è¯´æ˜"
                        }}
                      ]
                    }}
                  ]
                }}
              ]
            }}
          ],
          "overall_scoring_method": "æ•´ä½“è¯„åˆ†æ–¹æ³•è¯´æ˜",
          "total_possible_score": "æ‰€æœ‰è¡¨æ ¼çš„æ€»åˆ†"
        }}
        """
        # åˆ›å»ºæç¤ºæ¨¡æ¿
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("placeholder", "{messages}"),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}"),
        ])

        # åˆ›å»ºä»£ç†
        agent = create_tool_calling_agent(self.llm, self.tools, prompt)
        return AgentExecutor(agent=agent, tools=self.tools, verbose=True)

    def load_chapters(self, doc_path: str) -> List[str]:
        """åŠ è½½å¹¶åˆ†å‰²æ–‡æ¡£ç« èŠ‚"""
        processor = WordDocumentProcessor(str(self.chapters_dir))
        chapter_names = processor.extract_chapters(doc_path)
        return chapter_names

    async def find_review_principles_stream(self, chapter_names: List[str], threshold: float = 0.01) -> AsyncGenerator[
        Dict[str, Any], None]:
        """ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹æŸ¥æ‰¾åŒ…å«è¯„å®¡åŸåˆ™çš„ç« èŠ‚"""
        yield {"status": "start", "data": "å¼€å§‹åˆ†æå„ç« èŠ‚ä»¥æŸ¥æ‰¾è¯„å®¡åŸåˆ™..."}

        from langchain.prompts import (
            ChatPromptTemplate,
            SystemMessagePromptTemplate,
            HumanMessagePromptTemplate,
        )

        # æ„å»ºç« èŠ‚åˆ†ææç¤º
        analysis_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(
                """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©æ‰‹ã€‚
        ä½ çš„ä»»åŠ¡æ˜¯åˆ†ææ–‡æ¡£ç« èŠ‚ï¼Œæ‰¾å‡ºåŒ…å«è¯„å®¡åŸåˆ™ã€è¯„åˆ†æ ‡å‡†æˆ–è¯„åˆ†è§„åˆ™çš„ç« èŠ‚ã€‚

        è¯„å®¡åŸåˆ™/è¯„åˆ†æ ‡å‡†çš„ç‰¹å¾ï¼š
        1. åŒ…å«â€œè¯„åˆ†æ ‡å‡†â€ã€â€œè¯„åˆ†è§„åˆ™â€ã€â€œè¯„å®¡åŸåˆ™â€ç­‰å…³é”®è¯ã€‚
        2. åŒ…å«å…·ä½“çš„åˆ†æ•°ã€åˆ†å€¼ã€å¾—åˆ†è®¡ç®—æ–¹æ³•ã€‚
        3. æè¿°è¯„ä»·æ ‡å‡†å’Œè¯„ä»·ç»´åº¦ã€‚
        4. åŒ…å«è¯„åˆ†ç»†åˆ™æˆ–è¯„åˆ†æµç¨‹ã€‚

        è¯·åˆ†æä»¥ä¸‹ç« èŠ‚åˆ—è¡¨åŠå†…å®¹ï¼Œè¿”å›æœ€ç¬¦åˆæ¡ä»¶çš„ç« èŠ‚åç§°ï¼›è‹¥æ— ç¬¦åˆï¼Œåˆ™è¿”å›â€œæœªæ‰¾åˆ°â€ã€‚"""
            ),
            HumanMessagePromptTemplate.from_template(
                "ç« èŠ‚åˆ—è¡¨å’Œå†…å®¹ï¼š\n{chapters_info}"
            ),
        ])

        # å‡†å¤‡ç« èŠ‚ä¿¡æ¯
        chapters_info = []
        for chapter_name in chapter_names:
            content = self.chapter_reader._run(chapter_name)
            preview = content
            chapters_info.append(f"ç« èŠ‚å: {chapter_name}\nå†…å®¹é¢„è§ˆ: {preview}\n" + "=" * 50)
        chapters_text = "".join(chapters_info)
        print(len(chapters_info))
        # æ ¼å¼åŒ– promptï¼Œå¾—åˆ° ChatPromptValue
        prompt_value = analysis_prompt.format_prompt(chapters_info=chapters_text)

        # è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼
        messages = []
        for message in prompt_value.messages:
            # LangChain æ¶ˆæ¯ç±»å‹æ˜ å°„
            if message.__class__.__name__ == "SystemMessage":
                role = "system"
            elif message.__class__.__name__ == "HumanMessage":
                role = "user"
            elif message.__class__.__name__ == "AIMessage":
                role = "assistant"
            else:
                role = "user"  # é»˜è®¤ä¸ºç”¨æˆ·æ¶ˆæ¯

            messages.append({
                "role": role,
                "content": message.content
            })
        buffer = ""
        try:
            async for chunk in self.llm.astream(messages):
                token = chunk.content
                buffer += token
        except Exception as e:
            yield {"status": "error", "data": f"æµå¤„ç†é”™è¯¯: {str(e)}"}
            return
        result_chapter = buffer.strip()
        res_norm = normalize(result_chapter)
        yield {"status": "model_done", "data": f"æ¨¡å‹æ¨èç« èŠ‚: {result_chapter}"}
        if result_chapter == "æœªæ‰¾åˆ°":
            yield {"status": "complete", "data": "æœªæ‰¾åˆ°ç›¸å…³ç« èŠ‚"}
            return

        # å¯¹æ¯ä¸ªç« èŠ‚åè®¡ç®—ç›¸ä¼¼åº¦ï¼Œé€‰å‡ºæœ€é«˜çš„
        best_name, best_score = None, 0.0
        for name in chapter_names:
            name_norm = normalize(name)
            score = lcs_similarity(res_norm, name_norm)
            if score > best_score:
                best_score, best_name = score, name

        # æ£€æŸ¥æ˜¯å¦é€šè¿‡é˜ˆå€¼
        if best_score >= threshold:
            full_content = self.chapter_reader._run(best_name)  # æˆ–è€…ä½ çš„è¯»å–å‡½æ•°
            yield {"status": "complete", "found": True, "chapter": best_name, "content": full_content,
                   "all_chapters": chapter_names, "data": ""}

    async def learn_review_rules_stream(
            self,
            content: str,
            all_chapters: List[str],
            agent=None
    ) -> AsyncGenerator[Union[Dict[str, str], Tuple[str, Dict[str, str]]], None]:
        """ä½¿ç”¨ä»£ç†å­¦ä¹ è¯„å®¡è§„åˆ™ï¼Œæ”¯æŒæŒ‰ä¸‰éƒ¨åˆ†ç»†åˆ™åˆ†åˆ«æå–å¹¶è¿”å›æƒé‡å’ŒåŸæ–‡"""
        score_mapping = {
            "æŠ€æœ¯è¯„åˆ†ç»†åˆ™": "technical",
            "å•†åŠ¡è¯„åˆ†ç»†åˆ™": "business",
            "ä»·æ ¼è¯„åˆ†ç»†åˆ™": "price"
        }
        sections = ["æŠ€æœ¯è¯„åˆ†ç»†åˆ™", "å•†åŠ¡è¯„åˆ†ç»†åˆ™", "ä»·æ ¼è¯„åˆ†ç»†åˆ™"]
        combined_weights: Dict[str, str] = {}
        raw_sections: Dict[str, str] = {}
        import asyncio
        yield {"status": "start", "data": f"å¼€å§‹å­¦ä¹ è¯„å®¡è§„åˆ™ï¼Œå…±{len(sections)}éƒ¨åˆ†...è¯·ç­‰å¾…"}

        def create_analysis_prompt(section):
            system_message = f"""
                ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç»™å®šçš„è¯„å®¡åŸåˆ™æ–‡æ¡£ï¼Œæå–å‡ºå…¶ä¸­æ‰€æœ‰çš„å…³äº\"{section}\"è¯„åˆ†è¡¨æ ¼ã€‚
                é‡è¦æé†’ï¼š
                1. ä»”ç»†æŸ¥çœ‹æ•´ä¸ªæ–‡æ¡£ï¼Œä¸è¦é—æ¼ä»»ä½•ä¸€ä¸ªåŒ…å«è¯„åˆ†æ ‡å‡†çš„è¡¨æ ¼ã€‚
                2. æ¯ä¸ªç›¸å…³è¡¨æ ¼éƒ½è¦å®Œæ•´æå–ï¼ŒåŒ…æ‹¬è¡¨æ ¼æ ‡é¢˜ã€åˆ†å€¼èŒƒå›´ã€è¯„åˆ†é¡¹ç›®ç­‰ã€‚
                3. å¿…é¡»ä¸”ä»…æŒ‰ç…§ä¸¥æ ¼çš„JSONæ ¼å¼è¾“å‡ºï¼Œæ‰€æœ‰keyå¿…é¡»ä½¿ç”¨è‹±æ–‡ã€‚æ‰€æœ‰çš„valueå†…å®¹ä¿æŒä¸­æ–‡ã€‚
                è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
                - æœ€å¤–å±‚å¿…é¡»åŒ…å« scoring_tables æ•°ç»„ã€‚
                - æ¯ä¸ªè¡¨æ ¼åŒ…å« table_name, table_description, total_score_range, weight, sectionsã€‚
                - æ¯ä¸ªsectionåŒ…å« section_name, section_score_range, subsectionsã€‚
                - æ¯ä¸ªsubsectionåŒ…å« subsection_name, subsection_score_range, itemsã€‚
                - æ¯ä¸ªitemåŒ…å« item_name, description, score_range, scoring_methodã€‚
                4. æ³¨æ„jsonç»“æ„ï¼Œæœ€å¤–å±‚åªèƒ½æœ‰scoring_tablesï¼Œå½“scoring_tableså¯¹åº”å†…å®¹çš„åˆ—è¡¨é—­åˆåï¼Œç«‹å³ç»“æŸè¯¥å­—å…¸ã€‚
                5. ç¡®ä¿å­—ç¬¦ä¸²jsonç»“æ„å¯è¢«json.loadsè§£æ, è§£æå®Œåä¼šè½¬å­—ç¬¦ä¸²å‘ˆç°ç»™ç”¨æˆ·ï¼Œè¦æ±‚å†…å®¹æ˜¯user-friendlyçš„ã€‚
                """

            human_message = "æ–‡æ¡£å†…å®¹ï¼š\n{content}\n\næ‰€æœ‰ç« èŠ‚åˆ—è¡¨ï¼š{all_chapters}\n"

            return ChatPromptTemplate.from_messages([
                SystemMessagePromptTemplate.from_template(system_message),
                HumanMessagePromptTemplate.from_template(human_message)
            ])

        async def process_section(section: str) -> Tuple[str, Dict[str, str], str, bool]:
            """å¤„ç†å•ä¸ªsectionï¼Œè¿”å›(section_name, weights, part_data, is_skipped)"""
            # æ„å»º Prompt
            analysis_prompt = create_analysis_prompt(section)
            prompt_value = analysis_prompt.format_prompt(
                content=content,
                all_chapters=', '.join(all_chapters)
            )
            messages = []
            for msg in prompt_value.messages:
                if hasattr(msg, 'type'):
                    role = 'system' if msg.type == 'system' else 'user'
                else:
                    role = 'system' if 'System' in msg.__class__.__name__ else 'user'
                messages.append({"role": role, "content": msg.content})

            # ä½¿ç”¨å¼‚æ­¥è°ƒç”¨LLMï¼ˆå¦‚æœæ”¯æŒainvokeï¼‰
            if hasattr(self.llm, 'ainvoke'):
                response = await self.llm.ainvoke(messages)
            else:
                # å¦‚æœä¸æ”¯æŒainvokeï¼Œä½¿ç”¨çº¿ç¨‹æ± å¼‚æ­¥æ‰§è¡Œ
                response = await asyncio.get_event_loop().run_in_executor(
                    None, self.llm.invoke, messages
                )

            buffer = response.content

            # æ£€æŸ¥æ˜¯å¦è·³è¿‡
            if "æœªæ‰¾åˆ°è¯„åˆ†è¡¨æ ¼" in buffer:
                return section, {}, "", True

            # è§£æJSON
            json_text = buffer
            json_text = re.sub(r"^.*?```json\s*", "", json_text, flags=re.S)
            json_text = re.sub(r"\s*```.*$", "", json_text, flags=re.S)
            json_text = json_text.replace('\r', ' ').replace('\n', ' ')

            open_count = json_text.count('{')
            close_count = json_text.count('}')
            if open_count > close_count:
                json_text += '}' * (open_count - close_count)
            last = json_text.rfind('}')
            if last != -1:
                json_text = json_text[: last + 1]

            part_data = json.loads(json_text)

            # æå–æƒé‡å‡½æ•°
            def extract_weights(data: Dict) -> Dict[str, str]:
                weights: Dict[str, str] = {}
                for table in data.get("scoring_tables", []):
                    name = table.get("table_name", "æœªçŸ¥è¡¨æ ¼")
                    if "weight" in table:
                        weights[name] = table["weight"]
                    for sec in table.get("sections", []):
                        sec_name = sec.get("section_name", "æœªçŸ¥ç« èŠ‚")
                        if "weight" in sec:
                            weights[f"{name} - {sec_name}"] = sec["weight"]
                        for sub in sec.get("subsections", []):
                            sub_name = sub.get("subsection_name", "æœªçŸ¥å­ç« èŠ‚")
                            if "weight" in sub:
                                weights[f"{name} - {sec_name} - {sub_name}"] = sub["weight"]
                            for item in sub.get("items", []):
                                item_name = item.get("item_name", "æœªçŸ¥é¡¹ç›®")
                                if "weight" in item:
                                    weights[f"{name} - {sec_name} - {sub_name} - {item_name}"] = item["weight"]
                return weights

            sec_weights = extract_weights(part_data)
            self._process_rules_data(part_data)

            return section, sec_weights, part_data, False

        # é¢„å¯åŠ¨æ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
        section_tasks = []
        for section in sections:
            task = asyncio.create_task(process_section(section))
            section_tasks.append((section, task))

        # æŒ‰é¡ºåºå¤„ç†æ¯ä¸ªsectionçš„ç»“æœ
        for i, (section, task) in enumerate(section_tasks):
            yield {"status": "section_start", "section": section}

            # ç­‰å¾…å½“å‰sectionçš„LLMå¤„ç†å®Œæˆ
            section_name, sec_weights, part_data, is_skipped = await task

            if is_skipped:
                yield {"status": "section_skip", "message": section, "data": "æœªæ‰¾åˆ°è¯„åˆ†è¡¨æ ¼"}
                continue

            # æ›´æ–°æƒé‡
            combined_weights.update(sec_weights)

            # å½“å‰sectionçš„å†…å®¹
            section_content = []
            async for chunk in json_to_readable(part_data):
                section_content.append(chunk)

            # åœ¨æµå¼è¾“å‡ºå®Œæˆåï¼Œä¿å­˜å½“å‰sectionçš„å†…å®¹
            raw_sections[score_mapping[section]] = "".join(section_content)
            yield {"status": "process", "data": section + "éƒ¨åˆ†å­¦ä¹ å®Œæ¯•", "message": ""}

        print("\nâœ… æ‰€æœ‰è¯„åˆ†è¡¨æ ¼å­¦ä¹ å®Œæˆï¼å¯ä»¥å¼€å§‹ä¼ å…¥æ–‡æ¡£è¿›è¡Œè¯„åˆ†ã€‚")
        yield {"status": "end", "message": [combined_weights, raw_sections], "data": ""}
    def _display_table_summary(self):
        """æ˜¾ç¤ºè¡¨æ ¼æ±‡æ€»ä¿¡æ¯"""
        print("\nğŸ“Š è¯„åˆ†è¡¨æ ¼æ±‡æ€»:")

        for table_info in self.scoring_tables:
            print(f"\nã€{table_info['name']}ã€‘")
            if table_info['total_score_range']:
                print(f"  åˆ†å€¼èŒƒå›´: {table_info['total_score_range']}")
            if table_info['weight']:
                print(f"  æƒé‡: {table_info['weight']}")

            # æŒ‰å¤§é¡¹åˆ†ç»„æ˜¾ç¤ºè§„åˆ™
            current_section = ""
            for rule in table_info['rules']:
                if hasattr(rule, 'section') and rule.section != current_section:
                    current_section = rule.section
                    print(f"  â””â”€ {current_section} ({rule.section_score_range})")

                item_name = rule.name.split(' - ')[-1]  # åªæ˜¾ç¤ºå…·ä½“é¡¹åç§°
                print(f"     â”œâ”€ {item_name} ({rule.score_range})")

    def _process_rules_data(self, rules_data: dict) -> bool:
        """å¤„ç†å¤šè¡¨æ ¼æ•°æ®å¹¶æ›´æ–°ç³»ç»ŸçŠ¶æ€"""

        # å¤„ç†æ‰€æœ‰è¯„åˆ†è¡¨æ ¼
        tables = rules_data.get("scoring_tables", [])
        if not tables:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•è¯„åˆ†è¡¨æ ¼")
            print(rules_data)
            return False

        print(f"âœ… å‘ç° {len(tables)} ä¸ªè¯„åˆ†è¡¨æ ¼")

        total_rules_count = 0

        for table_idx, table in enumerate(tables):
            table_name = table.get("table_name", f"è¡¨æ ¼{table_idx+1}")
            table_description = table.get("table_description", "")
            total_score_range = table.get("total_score_range", "")
            weight = table.get("weight", "")

            print(f"\nã€{table_name}ã€‘")
            if table_description:
                print(f"  æè¿°: {table_description}")
            if total_score_range:
                print(f"  åˆ†å€¼èŒƒå›´: {total_score_range}")
            if weight:
                print(f"  æƒé‡: {weight}")

            # å­˜å‚¨è¡¨æ ¼ä¿¡æ¯
            table_info = {
                "name": table_name,
                "description": table_description,
                "total_score_range": total_score_range,
                "weight": weight,
                "rules": []
            }

            # å¤„ç†è¡¨æ ¼ä¸­çš„è¯„åˆ†è§„åˆ™
            table_rules_count = 0
            for section in table.get("sections", []):
                section_name = section.get("section_name", "")
                section_score_range = section.get("section_score_range", "")

                for subsection in section.get("subsections", []):
                    subsection_name = subsection.get("subsection_name", "")
                    subsection_score_range = subsection.get("subsection_score_range", "")

                    for item in subsection.get("items", []):
                        # æ„å»ºå®Œæ•´çš„è§„åˆ™åç§°ï¼ŒåŒ…å«è¡¨æ ¼åç§°
                        full_name = f"{table_name} - {section_name} - {subsection_name} - {item.get('item_name', '')}"

                        rule = ReviewRule(
                            name=full_name,
                            criteria=item.get("description", ""),
                            score_range=item.get("score_range", ""),
                            details=item.get("scoring_method", "")
                        )

                        # æ·»åŠ å±‚çº§å’Œè¡¨æ ¼ä¿¡æ¯
                        rule.table_name = table_name
                        rule.section = section_name
                        rule.subsection = subsection_name
                        rule.section_score_range = section_score_range
                        rule.subsection_score_range = subsection_score_range
                        rule.table_weight = weight

                        self.review_rules.append(rule)
                        table_info["rules"].append(rule)
                        table_rules_count += 1
                        total_rules_count += 1

            self.scoring_tables.append(table_info)
            print(f"  åŒ…å« {table_rules_count} æ¡è¯„åˆ†è§„åˆ™")

        # ä¿å­˜æ•´ä½“è¯„åˆ†ä¿¡æ¯
        self.overall_scoring_method = rules_data.get("overall_scoring_method", "")
        self.total_possible_score = rules_data.get("total_possible_score", "")

        if self.review_rules:
            print(f"\nğŸ‰ æ€»å…±è¯†åˆ«åˆ° {total_rules_count} æ¡è¯„åˆ†è§„åˆ™ï¼Œåˆ†å¸ƒåœ¨ {len(tables)} ä¸ªè¡¨æ ¼ä¸­")

            if self.overall_scoring_method:
                print(f"æ•´ä½“è¯„åˆ†æ–¹æ³•: {self.overall_scoring_method}")
            if self.total_possible_score:
                print(f"æ€»åˆ†: {self.total_possible_score}")

            # æŒ‰è¡¨æ ¼åˆ†ç»„æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            self._display_table_summary()

            self.rules_learned = True
            return True
        else:
            print("âŒ æœªèƒ½è¯†åˆ«å‡ºä»»ä½•è¯„åˆ†è§„åˆ™")
            return False

    def _parse_review_rules(self, content: str) -> List[ReviewRule]:
        """è§£æè¯„å®¡è§„åˆ™"""
        rules = []

        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = [p.strip() for p in content.split('\n') if p.strip()]

        current_rule = None

        for paragraph in paragraphs:
            # æ£€æµ‹è§„åˆ™æ ‡é¢˜
            if self._is_rule_heading(paragraph):
                if current_rule:
                    rules.append(current_rule)

                current_rule = ReviewRule(
                    name=paragraph,
                    criteria="",
                    score_range=self._extract_score_range(paragraph),
                    details=""
                )
            elif current_rule:
                # ç´¯ç§¯è§„åˆ™è¯¦æƒ…
                if current_rule.criteria:
                    current_rule.criteria += " " + paragraph
                else:
                    current_rule.criteria = paragraph

        # æ·»åŠ æœ€åä¸€ä¸ªè§„åˆ™
        if current_rule:
            rules.append(current_rule)

        return rules

    def _is_rule_heading(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºè§„åˆ™æ ‡é¢˜"""
        patterns = [
            r'^\d+[\.ã€]',  # æ•°å­—ç¼–å·
            r'^[ï¼ˆ(]\d+[ï¼‰)]',  # æ‹¬å·ç¼–å·
            r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€.]',  # ä¸­æ–‡æ•°å­—
            r'^[A-Z][a-z]*:',  # è‹±æ–‡æ ‡é¢˜
        ]

        for pattern in patterns:
            if re.search(pattern, text):
                return True

        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¯„åˆ†å…³é”®è¯
        score_keywords = ["åˆ†", "è¯„åˆ†", "å¾—åˆ†", "åˆ†å€¼", "åˆ†æ•°"]
        return any(keyword in text for keyword in score_keywords)

    def _extract_score_range(self, text: str) -> str:
        """æå–åˆ†å€¼èŒƒå›´"""
        patterns = [
            r'(\d+)[-~è‡³åˆ°](\d+)åˆ†',
            r'æ»¡åˆ†(\d+)åˆ†',
            r'(\d+)åˆ†',
            r'(\d+)%'
        ]

        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return match.group(0)

        return ""

    async def score_document_stream(self, data_folder: str, chapter_name: str, section_name: str, weights:Dict[str, float] = None)-> AsyncGenerator[Union[Dict[str, Any], str], None]:
        """
        ä¸ºæŒ‡å®šéƒ¨åˆ†çš„æ–‡æ¡£è¿›è¡Œè¯„åˆ†

        Args:
            data_folder: æ–‡æ¡£æ–‡ä»¶å¤¹è·¯å¾„
            chapter_name: ç« èŠ‚åç§°
            section_name: è¯„åˆ†éƒ¨åˆ†åç§°ï¼ˆå¦‚ï¼šæŠ€æœ¯è¯„åˆ†ç»†åˆ™ã€å•†åŠ¡è¯„åˆ†ç»†åˆ™ã€ä»·æ ¼è¯„åˆ†ç»†åˆ™ï¼‰
            weights: è¯¥éƒ¨åˆ†çš„æƒé‡é…ç½®

        Returns:
            tuple: (è¯„åˆ†æ–‡æœ¬, å¾—åˆ†, è¯¦ç»†ä¿¡æ¯åˆ—è¡¨)
        """
        if not getattr(self, 'rules_learned', False):
            yield {"status": "error", "data": "è¯„å®¡è§„åˆ™å°šæœªå­¦ä¹ ï¼Œè¯·å…ˆå­¦ä¹ è¯„å®¡åŸåˆ™"}
            return

        yield {"status": "start", "data": f"å¼€å§‹è¯„åˆ†ç« èŠ‚ï¼š{chapter_name} éƒ¨åˆ†ï¼š{section_name}"}

        doc_files = [f for f in os.listdir(data_folder) if f.lower().endswith('.docx')]
        if not doc_files:
            yield {"status": "error", "data": f"åœ¨æ–‡ä»¶å¤¹ {data_folder} ä¸­æœªæ‰¾åˆ°ä»»ä½•Wordæ–‡æ¡£"}
            return

        score_mapping = {
            "technical": "æŠ€æœ¯è¯„åˆ†ç»†åˆ™",
            "business": "å•†åŠ¡è¯„åˆ†ç»†åˆ™",
            "price": "ä»·æ ¼è¯„åˆ†ç»†åˆ™"
        }
        section_rules = [rule for rule in self.review_rules if rule.name.startswith(score_mapping[section_name])]
        if not section_rules:
            yield {"status": "error", "data": f"æœªæ‰¾åˆ° {section_name} ç›¸å…³çš„è¯„å®¡è§„åˆ™"}
            return

        # æ„å»ºè§„åˆ™ä¿¡æ¯
        rules_info: List[str] = []
        for rule in section_rules:
            text = f"è§„åˆ™ï¼š{rule.name}\næ ‡å‡†ï¼š{rule.criteria}\nåˆ†å€¼ï¼š{rule.score_range}\n"
            if rule.details:
                text += f"è¦ç‚¹ï¼š{rule.details}\n"
            if rule.reference_paragraphs:
                paras = self.processor.get_paragraphs(chapter_name)
                ref_texts = [paras[i] for i in rule.reference_paragraphs if i in paras]
                text += "å‚è€ƒæ®µè½ï¼š" + " | ".join(ref_texts) + "\n"
            rules_info.append(text)

        # å¤„ç†æƒé‡å½’ä¸€åŒ–
        if weights is not None and isinstance(weights, dict):
            try:
                # å°†å­—ç¬¦ä¸²å€¼è½¬æ¢ä¸ºæ•°å­—å¹¶è®¡ç®—æ€»å’Œ
                numeric_weights = {key: float(value) for key, value in weights.items()}
                total_weight = sum(numeric_weights.values())

                if total_weight == 100:
                    # å°†æ‰€æœ‰å€¼é™¤ä»¥100è¿›è¡Œå½’ä¸€åŒ–
                    weights = {key: value / 100 for key, value in numeric_weights.items()}
                    print(
                        f"æƒé‡æ€»å’Œä¸º100ï¼Œå·²å½’ä¸€åŒ–: åŸå§‹æƒé‡æ€»å’Œ={total_weight} -> å½’ä¸€åŒ–åæƒé‡æ€»å’Œ={sum(weights.values())}")
                else:
                    print(f"æƒé‡æ€»å’Œä¸º{total_weight}ï¼Œæ— éœ€å½’ä¸€åŒ–")
                    weights = numeric_weights
            except (ValueError, TypeError) as e:
                print(f"æƒé‡è½¬æ¢å¤±è´¥: {e}")
        # å‡†å¤‡æ‰€æœ‰æ–‡æ¡£å†…å®¹
        contents: List[str] = []
        for fname in doc_files:
            path = os.path.join(data_folder, fname)
            try:
                doc = Document(path)
                content = "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
                contents.append(f"æ–‡ä»¶å: {fname}\nå†…å®¹:\n{content}")
            except Exception:
                continue
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ç”¨äºprompt
        first_key = next(iter(weights))
        weights_str = str(weights[first_key])
        # æ„å»ºprompt
        prompt = ChatPromptTemplate.from_messages([
            ("system", "è¯·æ ¹æ®ä»¥ä¸‹è¯„å®¡è§„åˆ™åŠå‚è€ƒæ®µè½ç»™å‡ºè¿™ä¸€éƒ¨åˆ†çš„æƒé‡ä¸è¯„åˆ†ï¼š\n{rules}"),
            ("human", "ä½ ä¼šè¢«ç»™äºˆè§„åˆ™ä¸­æŸä¸€éƒ¨åˆ†çš„ä¿¡æ¯ã€‚è¯·å®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š\n"
                      "1. æ‰¾å‡ºå¾…è¯„åˆ†æ–‡æ¡£çš„å†…å®¹å±äºé‚£ä¸€ç±»è§„åˆ™\n"
                      "2. ä¾æ®è§„åˆ™ä¸ºè¯¥éƒ¨åˆ†è¯„åˆ†\n"
                      "3. å°†è®¡ç®—è¿‡ç¨‹å°è£…åœ¨Pythonå¯æ‰§è¡Œè¡¨è¾¾å¼ä¸­\n"
                      "4. è¡¨è¾¾å¼åªèƒ½ä½¿ç”¨ `+ - * / abs( )` ç­‰å†…ç½®è¿ç®—ï¼Œä¸è¦å‡ºç°å…¶ä»–ä»»ä½•ä¸­æ–‡æˆ–å¤æ‚æ ‡è®°ã€‚ç»™å‡ºè¡¨è¾¾å¼æ—¶ï¼Œä¹Ÿè¦ç»™å‡ºå¯¹åº”è§„åˆ™çš„æƒé‡ï¼Œæƒé‡ä¸º:\n" + weights_str + "\n"
                      "5. å…ˆæ¨å¯¼ç»™å‡ºæ¯ä¸ªåˆ†æ•°çš„åŸå› ï¼Œç„¶åä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ¥åŒ…è£¹è®¡ç®—çš„è¡¨è¾¾å¼ï¼š<calc>{{è¡¨è¾¾å¼}}</calc>\n\n"
                     "ä¾‹å¦‚ï¼šä½ åˆ¤æ–­å¾—åˆ†ä¸º5,5,0,10,20ã€‚è¯·ä½ å…ˆç»™å‡ºè¿™æ ·æ‰“åˆ†çš„åŸå› ï¼Œç„¶åä»¥: <calc> (5+5+0+10+20) * æƒé‡ </calc> ç»“å°¾\n\n"
                     "å…¶ä¸­ï¼Œå°æ‹¬å·åŒ…è£¹è¡¨è¾¾å¼æ˜¯æŸä¸€éƒ¨åˆ†çš„è¯„åˆ†ç»†åˆ™ç´¯ç§¯çš„è¡¨è¾¾å¼ï¼Œç³»æ•°æ˜¯å¯¹åº”éƒ¨åˆ†çš„æƒé‡ã€‚æ³¨æ„,æ¯ä¸ªéƒ¨åˆ†ä¹˜ä¸Šæƒé‡åæ‰æ˜¯æœ€ç»ˆç»“æœã€‚ç¼ºå°‘çš„ä¿¡æ¯è¯·ä¸è¦å‡è®¾ï¼Œä¸€å¾‹æŒ‰ç…§æ²¡æœ‰è¿›è¡Œè€ƒè™‘ã€‚è¯·æŒ‰ç…§æˆ‘ç»™ä½ çš„æ ¼å¼è¾“å‡ºã€‚å¾…è¯„åˆ†æ–‡æ¡£å†…å®¹ï¼š\n\n{content}"
                      "6. æ¯ä¸ªéƒ¨åˆ†éƒ½åº”æŒ‰è§„åˆ™çš„é¡ºåºæ‰“åˆ†ï¼Œå³ä½¿æ˜¯0åˆ†ä¹Ÿè¦æ‰“ä¸Š, åªåœ¨æœ€åç»“æœé‡‡ç”¨<calc>æ ¼å¼è¾“å‡ºã€‚ä¸è¦é‡å¤è¾“å‡ºå†…å®¹ï¼Œä¸è¦é‡å¤æ‰“åˆ†ã€‚")
        ])
        merged_content = "\n" + "=" * 40 + "\n".join(contents)

        params = {"rules": "".join(rules_info), "content": merged_content}

        # ä½¿ç”¨ format_prompt è€Œä¸æ˜¯ format
        prompt_value = prompt.format_prompt(**params)

        # è½¬æ¢ä¸º OpenAI æ ¼å¼çš„æ¶ˆæ¯
        messages = []
        for msg in prompt_value.messages:
            if hasattr(msg, 'type'):
                # æ–°ç‰ˆæœ¬ LangChain
                role = "system" if msg.type == "system" else "user" if msg.type == "human" else "assistant"
            else:
                # é€šè¿‡ç±»ååˆ¤æ–­
                role = "system" if "System" in msg.__class__.__name__ else "user"

            messages.append({"role": role, "content": msg.content})

        buffer = ""
        try:
            async for chunk in self.llm.astream(messages):
                token = chunk.content
                buffer += token
                yield {"status": "stream", "message": section_name, "data": token}
        except Exception as e:
            yield {"status": "error", "data": f"æµå¤„ç†é”™è¯¯: {str(e)}"}
            return
        print(buffer)
        res_text = buffer.strip()
        calc_match = re.search(r'<calc>(.*?)</calc>', res_text, re.DOTALL)

        if calc_match:
            calc_expr = calc_match.group(1).strip()

            # è®¡ç®—å¾—åˆ†
            section_score = safe_eval(calc_expr)

            # æ¸…ç†å“åº”æ–‡æœ¬æ ¼å¼
            if res_text.startswith("```"):
                res_text = re.sub(r"^```(json)?", "", res_text).rstrip("`")

            document_results = {
                "status": "section_done",
                "message":{"section": section_name,"response": res_text.strip(),"calc_expression": calc_expr},
                "data": section_score,
            }

            yield  document_results
            return

        else:
            yield {
                "status": "error",
                "message":{"section": section_name,"response": res_text},
                "data": "æœªæ‰¾åˆ°è®¡ç®—è¡¨è¾¾å¼"
            }
            return

    # å¦‚æœéœ€è¦æµå¼è¿”å›ç‰ˆæœ¬ï¼Œå¯ä»¥ä½¿ç”¨è¿™ä¸ªç‰ˆæœ¬
    async def process_multiple_image_analysis_with_llm_stream(self, image_analysis_results, all_details, weights_str):
        """è°ƒç”¨å¤§æ¨¡å‹å¤„ç†å¤šä¸ªæ–‡ä»¶çš„å›¾ç‰‡åˆ†æç»“æœ - æµå¼ç‰ˆæœ¬"""
        # æ„å»ºpromptæ¨¡æ¿
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             "è¯·æ ¹æ®ä»¥ä¸‹è¯„å®¡è§„åˆ™ç»¼åˆåˆ†ææŠ•æ ‡æ–‡ä»¶çš„å›¾ç‰‡è¯†åˆ«ç»“æœå’Œè¯„åˆ†è¯¦æƒ…ã€‚"),
            ("human", "ä½ ä¼šè¢«ç»™äºˆå¤šä¸ªæ–‡ä»¶çš„å›¾ç‰‡åˆ†æç»“æœå’Œè¯„åˆ†è¯¦æƒ…ã€‚è¯·å®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š\n"
                      "1. ç»¼åˆåˆ†ææ‰€æœ‰æ–‡ä»¶çš„å›¾ç‰‡è¯†åˆ«ç»“æœ\n"
                      "2. å¯¹æ¯”å›¾ç‰‡ä¿¡æ¯ä¸åŸå§‹è¯„åˆ†è¯¦æƒ…\n"
                      "3. æ ¹æ®è¯„åˆ†è§„åˆ™å’Œæ–°æ·»åŠ çš„é¢å¤–æ–‡ä»¶å›¾ç‰‡ä¿¡æ¯ï¼Œæ›´æ–°è¯„åˆ†\n"
                      "4. æä¾›ç»¼åˆè¯„ä¼°å’Œä¸“ä¸šå»ºè®®,è¾“å‡ºæ ¼å¼è¯·å¯¹ç”¨æˆ·å‹å¥½\n\n"
                      "5. å°†è®¡ç®—è¿‡ç¨‹å°è£…åœ¨Pythonå¯æ‰§è¡Œè¡¨è¾¾å¼ä¸­\n"
                      "6. è¡¨è¾¾å¼åªèƒ½ä½¿ç”¨ `+ - * / abs( )` ç­‰å†…ç½®è¿ç®—ï¼Œä¸è¦å‡ºç°å…¶ä»–ä»»ä½•ä¸­æ–‡æˆ–å¤æ‚æ ‡è®°ã€‚ç»™å‡ºè¡¨è¾¾å¼æ—¶ï¼Œä¹Ÿè¦ç»™å‡ºå¯¹åº”è§„åˆ™çš„æƒé‡ï¼Œæƒé‡ä¸º:\n" + str(weights_str) + "\n"
                      "7. å…ˆæ¨å¯¼ç»™å‡ºæ¯ä¸ªåˆ†æ•°çš„åŸå› ï¼Œç„¶åä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ¥åŒ…è£¹è®¡ç®—çš„è¡¨è¾¾å¼ï¼š<calc>{{è¡¨è¾¾å¼}}</calc>\n\n"
                     "ä¾‹å¦‚ï¼šä½ åˆ¤æ–­å¾—åˆ†ä¸º5,5,0,10,20ã€‚è¯·ä½ å…ˆç»™å‡ºè¿™æ ·æ‰“åˆ†çš„åŸå› ï¼Œç„¶åä»¥: <calc> (5+5+0+10+20) * æƒé‡ </calc> ç»“å°¾\n\n"
                     "å…¶ä¸­ï¼Œå°æ‹¬å·åŒ…è£¹è¡¨è¾¾å¼æ˜¯æŸä¸€éƒ¨åˆ†çš„è¯„åˆ†ç»†åˆ™ç´¯ç§¯çš„è¡¨è¾¾å¼ï¼Œç³»æ•°æ˜¯å¯¹åº”éƒ¨åˆ†çš„æƒé‡ã€‚æ³¨æ„,æ¯ä¸ªéƒ¨åˆ†ä¹˜ä¸Šæƒé‡åæ‰æ˜¯æœ€ç»ˆç»“æœã€‚ç¼ºå°‘çš„ä¿¡æ¯è¯·ä¸è¦å‡è®¾ï¼Œä¸€å¾‹æŒ‰ç…§æ²¡æœ‰è¿›è¡Œè€ƒè™‘ã€‚è¯·æŒ‰ç…§æˆ‘ç»™ä½ çš„æ ¼å¼è¾“å‡ºã€‚"
                      "8. æ¯ä¸ªéƒ¨åˆ†éƒ½åº”æŒ‰è§„åˆ™çš„é¡ºåºæ‰“åˆ†ï¼Œå³ä½¿æ˜¯0åˆ†ä¹Ÿè¦æ‰“ä¸Š, åªåœ¨æœ€åç»“æœé‡‡ç”¨<calc>æ ¼å¼è¾“å‡ºã€‚ä¸è¦é‡å¤è¾“å‡ºå†…å®¹ï¼Œä¸è¦é‡å¤æ‰“åˆ†ã€‚"
                      "## é¢å¤–æ–‡ä»¶å›¾ç‰‡ä¿¡æ¯ï¼š\n{image_info}\n\n"
                      "## æœªå¾—åˆ°é¢å¤–æ–‡ä»¶å›¾ç‰‡ä¿¡æ¯æ—¶çš„è¯„åˆ†ï¼š\n{original_details}\n\n"
                      "è¯·æ ¹æ®è¯„åˆ†è§„åˆ™å’Œæ–°æ·»åŠ çš„é¢å¤–æ–‡ä»¶å›¾ç‰‡ä¿¡æ¯ï¼Œæ›´æ–°ä½ æœªå¾—åˆ°é¢å¤–æ–‡ä»¶å›¾ç‰‡ä¿¡æ¯æ—¶çš„è¯„åˆ†ã€‚")
        ])
        # å‡†å¤‡å‚æ•°
        params = {
            # "rules": self.review_rules,
            "image_info": json.dumps(image_analysis_results, ensure_ascii=False, indent=2),
            "original_details": json.dumps(all_details, ensure_ascii=False, indent=2)
        }
        # ä½¿ç”¨ format_prompt è€Œä¸æ˜¯ format
        prompt_value = prompt.format_prompt(**params)
        # è½¬æ¢ä¸º OpenAI æ ¼å¼çš„æ¶ˆæ¯
        messages = []
        for msg in prompt_value.messages:
            if hasattr(msg, 'type'):
                # æ–°ç‰ˆæœ¬ LangChain
                role = "system" if msg.type == "system" else "user" if msg.type == "human" else "assistant"
            else:
                # é€šè¿‡ç±»ååˆ¤æ–­
                role = "system" if "System" in msg.__class__.__name__ else "user"

            messages.append({"role": role, "content": msg.content})
        print(messages['content'])

        # æµå¼å¤„ç†
        buffer = ""
        try:
            async for chunk in self.llm.astream(messages):
                token = chunk.content
                buffer += token
                yield {"status": "stream", "message": "å›¾ç‰‡åˆ†æç»¼åˆå¤„ç†", "data": token}
        except Exception as e:
            yield {"status": "error", "data": f"æµå¤„ç†é”™è¯¯: {str(e)}"}
            return

        print(buffer)
        res_text = buffer.strip()
        calc_match = re.search(r'<calc>(.*?)</calc>', res_text, re.DOTALL)

        if calc_match:
            calc_expr = calc_match.group(1).strip()

            # è®¡ç®—å¾—åˆ†
            score = safe_eval(calc_expr)

            # æ¸…ç†å“åº”æ–‡æœ¬æ ¼å¼
            if res_text.startswith("```"):
                res_text = re.sub(r"^```(json)?", "", res_text).rstrip("`")

            document_results = {
                "status": "ImageScore_Done",
                "message": {"type":"æ–‡å­—å›¾ç‰‡å†…å®¹","response": res_text.strip(), "calc_expression": calc_expr},
                "data": score,
            }

            yield document_results
            return

        else:
            yield {
                "status": "error",
                "data": {"response": res_text},
                "message": "æœªæ‰¾åˆ°è®¡ç®—è¡¨è¾¾å¼"
            }
            return

# def main():
#     """ä¸»å‡½æ•°"""
#     print("=== Wordæ–‡æ¡£è¯„å®¡ç³»ç»Ÿ ===")
#
#     # åˆå§‹åŒ–ç³»ç»Ÿ
#     review_system = ReviewSystem()
#
#     # ç¬¬ä¸€æ­¥ï¼šè¾“å…¥åŒ…å«è¯„å®¡åŸåˆ™çš„æ–‡æ¡£
#     while True:
#         doc_path = input("\nè¯·è¾“å…¥åŒ…å«è¯„å®¡åŸåˆ™çš„Wordæ–‡æ¡£è·¯å¾„: ").strip()
#         if not doc_path:
#             continue
#
#         if not os.path.exists(doc_path):
#             print("æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥")
#             continue
#
#         try:
#             # åˆ†å‰²ç« èŠ‚
#             print("\næ­£åœ¨åˆ†å‰²æ–‡æ¡£ç« èŠ‚...")
#             chapter_names = review_system.load_chapters(doc_path)
#             print(f"å…±åˆ†å‰²å‡º {len(chapter_names)} ä¸ªç« èŠ‚: {', '.join(chapter_names)}")
#
#             # æŸ¥æ‰¾è¯„å®¡åŸåˆ™
#             print("\næ­£åœ¨æŸ¥æ‰¾è¯„å®¡åŸåˆ™...")
#             result = review_system.find_review_principles(chapter_names)
#
#             if result:
#                 chapter_name, content, all_chapters = result
#                 print(f"æ‰¾åˆ°è¯„å®¡åŸåˆ™ç« èŠ‚: {chapter_name}")
#
#                 # å­¦ä¹ è¯„å®¡è§„åˆ™ï¼ˆä¼ å…¥æ‰€æœ‰ç« èŠ‚åç§°ï¼‰
#                 print("\næ­£åœ¨å­¦ä¹ è¯„å®¡è§„åˆ™...")
#                 judge, weights = review_system.learn_review_rules(content, chapter_name, agent=review_system.agent)
#                 if judge:
#                     break
#                 else:
#                     print("è¯„å®¡è§„åˆ™å­¦ä¹ å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡æ¡£å†…å®¹")
#             else:
#                 print("æœªæ‰¾åˆ°è¯„å®¡åŸåˆ™ï¼Œè¯·ç¡®è®¤æ–‡æ¡£åŒ…å«è¯„åˆ†è§„åˆ™ç›¸å…³å†…å®¹")
#
#         except Exception as e:
#             print(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
#             import traceback
#             traceback.print_exc()
#
#     # ç¬¬äºŒæ­¥ï¼šè¯„åˆ†æ–°æ–‡æ¡£
#     while True: # weights
#         print("\n" + "=" * 50)
#         doc_path = input("è¯·è¾“å…¥éœ€è¦è¯„åˆ†çš„Wordæ–‡æ¡£çš„æ–‡ä»¶å¤¹è·¯å¾„ (è¾“å…¥'quit'é€€å‡º): ").strip()
#
#         if doc_path.lower() == 'quit':
#             break
#
#         if not os.path.exists(doc_path):
#             print("æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥")
#             continue
#
#         # è¿›è¡Œè¯„åˆ†
#         result, score, error = review_system.score_document(doc_path, chapter_name, weights)
#
#         if "error" in result:
#             print(f"è¯„åˆ†å¤±è´¥: {result['error']}")
#             continue
#
#         print(result)
#         print()
#         print("æœ€ç»ˆå¾—åˆ†: ", score)
#
# if __name__ == "__main__":
#     main()